{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementando nosso sistema de recomendação em Python usando Gradiente Descendente Estocástico (SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD e ALS são dois algoritmos amplamente utilizados para fatorar a matriz de scores (usuário x item) em duas matrizes de dimensões menores, com o benefício de fazer as atualizações do modelo mais fáceis.\n",
    "\n",
    "*Recapitulando algumas coisas*:\n",
    "- **Filtragem Colaborativa** tem como principal vantagem o fato de ser capaz de recomendar itens complexos sem nenhum conhecimento anterior do item.\n",
    "- **Baseados em Memória** usam a **similaridade** entre itens ou usuários, ex. usando a similaridade de cossenos.  \n",
    "- **Baseados em Modelos** usam fatoração de matrizes.\n",
    "\n",
    " *O objetivo principal do algoritmo de fatoração de matrizes é modelar os ratings preditos através da minimização do erro quadrático relativo à matriz de fatores latentes de usuário $P$ e a matriz de fatores latentes de itens $Q$, sobre o conjunto de ratings reais:\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?\\underset{Q*&space;,&space;P*}{min}\\sum_{(u,i)\\epsilon&space;K&space;}(r_{ui}-P_u^TQ_i)^2&plus;\\lambda(\\left&space;\\|&space;Q_i&space;\\right&space;\\|^2&space;&plus;&space;\\left&space;\\|&space;P_u&space;\\right&space;\\|^2)$&space;&space;$(1)\" title=\"\\underset{q* , p*}{min}\\sum_{(u,i)\\epsilon K }(r_{ui}-q_i^Tp_u)^2+\\lambda(\\left \\| q_i \\right \\|^2 + \\left \\| p_u \\right \\|^2)\" />\n",
    "\n",
    "Onde $K$ é um conjunto de pares $(u,i)$ tal que o rating é conhecido no conjunto de treino: por exemplo, $r_{ui}$ é o rating do item $i$ dado pelo usuário $u$ no conjunto de treino, e $\\lambda$ é o parâmetro de regularização para evitar overfiting. O erro quadrático regularizado é a **função de perda** que você almeja minimizar. Depois de estimados $P$ e $Q$ através da minimização do erro quadrático, é possível prever os ratings desconhecidos pelo produto escalar dos fatores latentes dos usuários e dos itens.\n",
    "\n",
    "O **gradiente descendente estocástico (SGD)** ou **método dos mínimos quadrados alternados (ALS)** pode ser aplicado para minimizar a função de perda. Ambos *SGD* e *ALS* podem ser usados para aprendizagem em tempo real, ou seja, atualizar o modelo de maneira incremental a cada vez que um novo rating é registrado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui será utilizado o dataset MovieLens, onde você deve adicionar os arquivos descompactados do dataset em sua pasta de trabalho do Jupyter Notebook. O dataset pode ser baixado [aqui](http://files.grouplens.org/datasets/movielens/ml-100k.zip).\n",
    "Primeiro, leia o arquivo **u.data** que contém o dataset completo. Uma descrição rápida do dataset pode ser encontrada [aqui](http://files.grouplens.org/datasets/movielens/ml-100k-README.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users = 943 | Number of movies = 1682\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "header = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('./ml-100k/u.data', sep='\\t', names=header)\n",
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "print ('Number of users = ' + str(n_users) + ' | Number of movies = ' + str(n_items))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Você pode usar a biblioteca do [`scikit-learn`](http://scikit-learn.org/stable/) para dividir o dataset em duas porções de treino e teste. \n",
    "Ela mistura e divide os dados em dois datasets de acordo com a percentagem de exemplos de teste (``test_size``), que nesse caso é 0.25. O próximo passo será criar a matriz de ratings. Como teremos dados de treino e teste será necessário a criação de duas matrizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(df,test_size=0.25)\n",
    "\n",
    "train_data = pd.DataFrame(train_data)\n",
    "test_data = pd.DataFrame(test_data)\n",
    "\n",
    "# Create training and test matrix\n",
    "R = np.zeros((n_users, n_items))\n",
    "for line in train_data.itertuples():\n",
    "    R[line[1]-1, line[2]-1] = line[3]  \n",
    "\n",
    "T = np.zeros((n_users, n_items))\n",
    "for line in test_data.itertuples():\n",
    "    T[line[1]-1, line[2]-1] = line[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As matrizes $I$ e $I2$ servirão como um seletor de matrizes, elas separarão os ratings apropriados de acordo com a atualização das equações durante o treino sobre o dataset de treino (usando $I$) e de predição sobre o dataset de teste (usando $I2$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Index matrix for training data\n",
    "I = R.copy()\n",
    "I[I > 0] = 1\n",
    "I[I == 0] = 0\n",
    "\n",
    "# Index matrix for test data\n",
    "I2 = T.copy()\n",
    "I2[I2 > 0] = 1\n",
    "I2[I2 == 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradiente Descendente Estocástico com Regularização por Lambda Ponderado (SGD-WR)\n",
    "\n",
    "Ao utilizar Filtragem Colaborativa com Gradiente Descendente Estocástico, é necessário estimar duas matrizes - a matriz de fatores latentes do usuário $P$ e a matriz de fatores latentes dos itens $Q$. Após estimadas $P$ e $Q$, podem ser preditos os ratings desconhecidos através do produto escalar das matrizes de fatores latentes de usuário e item. <img src=\"https://latex.codecogs.com/gif.latex?\\hat&space;r_{ui}=P_u^TQ_i$&space;&space;$(2)\" title=\"\\hat r_{ui}=p_u^Tq_i\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict the unknown ratings through the dot product of the latent features for users and items \n",
    "def prediction(P,Q):\n",
    "    return np.dot(P.T,Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definição matemática do gradiente descendente estocástico quando utilizado para minimizar o erro quadrático regularizado (função de perda):\n",
    "\n",
    "Para atualizar $P$ e $Q$, pode-se utilizar o gradiente descendente estocástico onde tu itera sobre cada observação (linha) no conjunto de treino e atualiza $Q$ e $P$ da seguinte maneira:\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?Q_{i&plus;1}&space;=&space;Q_i&space;&plus;&space;\\gamma&space;(e_{ui}\\cdot&space;P_u-\\lambda\\cdot&space;Q_i)$&space;&space;$(3)\" title=\"Q_{i+1} = Q_i + \\gamma (e_{ui}\\cdot P_u-\\lambda\\cdot Q_i)\" />\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?P_{u&plus;1}&space;=&space;P_u&space;&plus;&space;\\gamma&space;(e_{ui}\\cdot&space;Q_i-\\lambda\\cdot&space;P_u)$&space;&space;$(4)\" title=\"P_{u+1} = P_u + \\gamma (e_{ui}\\cdot Q_i-\\lambda\\cdot P_u)\" />\n",
    "\n",
    "onde $\\gamma$ é a taxa de aprendizagem e $\\lambda$ é o parâmetro de regularização. O erro $(e)$ para o elemento $(u,i)$ é a diferença entre o rating predito e o rating real.\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?e_{ui}=r_{ui}-P_u^TQ_i$&space;&space;$(5)\" title=\"e_{ui}=r_{ui}-p_u^Tq_i\" />\n",
    "\n",
    "Iniciamos definindo os parâmetros do algoritmo $\\lambda$ (peso de regularização) e $k$ (dimensionalidade do espaço de fatores latentes), também iniciando as matrizes de fatores latentes $P$ e $Q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lmbda = 0.1 # Regularisation weight\n",
    "k = 20  # Dimensionality of the latent feature space\n",
    "m, n = R.shape  # Number of users and items\n",
    "n_epochs = 100  # Number of epochs\n",
    "gamma=0.01  # Learning rate\n",
    "\n",
    "P = 3 * np.random.rand(k,m) # Latent user feature matrix\n",
    "Q = 3 * np.random.rand(k,n) # Latent movie feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem várias métricas de avaliação, mas uma das mais populares utilizadas para avaliar a acurácia de ratings preditos é o Erro Quadrático Médio (RMSE), que vamos utilizar nesse tutorial:\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?RMSE&space;=\\sqrt{\\frac{1}{N}&space;\\sum&space;(r_i&space;-\\hat{r_i})^2} $&space;&space;$(6)\" title=\"RMSE =\\sqrt{\\frac{1}{N} \\sum (r_i -\\hat{r_i})^2}\" />\n",
    "\n",
    "onde $N$ é o número de observações (linhas), $r_i$ é o rating real para a observação (linha) $i$ e $\\hat{r_i}$ é o rating predito.\n",
    "Como desejamos considerar apenas os ratings preditos que estão presentes nos conjuntos de treino e teste, filtramos todos os outros ratings na matriz de predição usando ``I`` e ``R[R > 0]``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the RMSE\n",
    "def rmse(I,R,Q,P):\n",
    "    return np.sqrt(np.sum((I * (R - prediction(P,Q)))**2)/len(R[R > 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora implementaremos o SGD-WR onde utilizaremos as equações ``(3)``, ``(4)``, ``(5)`` definidas anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/100] train error: 3.757374, test error: 3.729510\n",
      "[Epoch 2/100] train error: 2.527801, test error: 2.725482\n",
      "[Epoch 3/100] train error: 2.178680, test error: 2.387775\n",
      "[Epoch 4/100] train error: 1.952283, test error: 2.160061\n",
      "[Epoch 5/100] train error: 1.774671, test error: 1.982352\n",
      "[Epoch 6/100] train error: 1.625151, test error: 1.835272\n",
      "[Epoch 7/100] train error: 1.497437, test error: 1.711932\n",
      "[Epoch 8/100] train error: 1.390087, test error: 1.609987\n",
      "[Epoch 9/100] train error: 1.301532, test error: 1.527047\n",
      "[Epoch 10/100] train error: 1.229141, test error: 1.459911\n",
      "[Epoch 11/100] train error: 1.169887, test error: 1.405270\n",
      "[Epoch 12/100] train error: 1.121002, test error: 1.360291\n",
      "[Epoch 13/100] train error: 1.080253, test error: 1.322779\n",
      "[Epoch 14/100] train error: 1.045931, test error: 1.291103\n",
      "[Epoch 15/100] train error: 1.016737, test error: 1.264049\n",
      "[Epoch 16/100] train error: 0.991673, test error: 1.240705\n",
      "[Epoch 17/100] train error: 0.969967, test error: 1.220367\n",
      "[Epoch 18/100] train error: 0.951010, test error: 1.202493\n",
      "[Epoch 19/100] train error: 0.934328, test error: 1.186659\n",
      "[Epoch 20/100] train error: 0.919545, test error: 1.172535\n",
      "[Epoch 21/100] train error: 0.906364, test error: 1.159857\n",
      "[Epoch 22/100] train error: 0.894545, test error: 1.148417\n",
      "[Epoch 23/100] train error: 0.883894, test error: 1.138045\n",
      "[Epoch 24/100] train error: 0.874253, test error: 1.128605\n",
      "[Epoch 25/100] train error: 0.865489, test error: 1.119980\n",
      "[Epoch 26/100] train error: 0.857490, test error: 1.112075\n",
      "[Epoch 27/100] train error: 0.850164, test error: 1.104809\n",
      "[Epoch 28/100] train error: 0.843428, test error: 1.098111\n",
      "[Epoch 29/100] train error: 0.837214, test error: 1.091922\n",
      "[Epoch 30/100] train error: 0.831462, test error: 1.086190\n",
      "[Epoch 31/100] train error: 0.826122, test error: 1.080869\n",
      "[Epoch 32/100] train error: 0.821147, test error: 1.075919\n",
      "[Epoch 33/100] train error: 0.816501, test error: 1.071306\n",
      "[Epoch 34/100] train error: 0.812148, test error: 1.066998\n",
      "[Epoch 35/100] train error: 0.808060, test error: 1.062968\n",
      "[Epoch 36/100] train error: 0.804210, test error: 1.059193\n",
      "[Epoch 37/100] train error: 0.800577, test error: 1.055650\n",
      "[Epoch 38/100] train error: 0.797140, test error: 1.052320\n",
      "[Epoch 39/100] train error: 0.793883, test error: 1.049185\n",
      "[Epoch 40/100] train error: 0.790789, test error: 1.046231\n",
      "[Epoch 41/100] train error: 0.787846, test error: 1.043443\n",
      "[Epoch 42/100] train error: 0.785040, test error: 1.040809\n",
      "[Epoch 43/100] train error: 0.782362, test error: 1.038317\n",
      "[Epoch 44/100] train error: 0.779801, test error: 1.035957\n",
      "[Epoch 45/100] train error: 0.777350, test error: 1.033719\n",
      "[Epoch 46/100] train error: 0.775000, test error: 1.031596\n",
      "[Epoch 47/100] train error: 0.772744, test error: 1.029579\n",
      "[Epoch 48/100] train error: 0.770576, test error: 1.027661\n",
      "[Epoch 49/100] train error: 0.768491, test error: 1.025836\n",
      "[Epoch 50/100] train error: 0.766484, test error: 1.024098\n",
      "[Epoch 51/100] train error: 0.764548, test error: 1.022441\n",
      "[Epoch 52/100] train error: 0.762682, test error: 1.020861\n",
      "[Epoch 53/100] train error: 0.760880, test error: 1.019352\n",
      "[Epoch 54/100] train error: 0.759138, test error: 1.017911\n",
      "[Epoch 55/100] train error: 0.757454, test error: 1.016534\n",
      "[Epoch 56/100] train error: 0.755825, test error: 1.015217\n",
      "[Epoch 57/100] train error: 0.754247, test error: 1.013956\n",
      "[Epoch 58/100] train error: 0.752719, test error: 1.012749\n",
      "[Epoch 59/100] train error: 0.751237, test error: 1.011593\n",
      "[Epoch 60/100] train error: 0.749799, test error: 1.010484\n",
      "[Epoch 61/100] train error: 0.748404, test error: 1.009421\n",
      "[Epoch 62/100] train error: 0.747049, test error: 1.008401\n",
      "[Epoch 63/100] train error: 0.745732, test error: 1.007422\n",
      "[Epoch 64/100] train error: 0.744453, test error: 1.006481\n",
      "[Epoch 65/100] train error: 0.743208, test error: 1.005578\n",
      "[Epoch 66/100] train error: 0.741996, test error: 1.004709\n",
      "[Epoch 67/100] train error: 0.740817, test error: 1.003873\n",
      "[Epoch 68/100] train error: 0.739669, test error: 1.003069\n",
      "[Epoch 69/100] train error: 0.738550, test error: 1.002295\n",
      "[Epoch 70/100] train error: 0.737459, test error: 1.001550\n",
      "[Epoch 71/100] train error: 0.736395, test error: 1.000831\n",
      "[Epoch 72/100] train error: 0.735357, test error: 1.000139\n",
      "[Epoch 73/100] train error: 0.734344, test error: 0.999472\n",
      "[Epoch 74/100] train error: 0.733355, test error: 0.998828\n",
      "[Epoch 75/100] train error: 0.732389, test error: 0.998206\n",
      "[Epoch 76/100] train error: 0.731445, test error: 0.997607\n",
      "[Epoch 77/100] train error: 0.730522, test error: 0.997027\n",
      "[Epoch 78/100] train error: 0.729620, test error: 0.996468\n",
      "[Epoch 79/100] train error: 0.728738, test error: 0.995927\n",
      "[Epoch 80/100] train error: 0.727874, test error: 0.995404\n",
      "[Epoch 81/100] train error: 0.727030, test error: 0.994898\n",
      "[Epoch 82/100] train error: 0.726202, test error: 0.994409\n",
      "[Epoch 83/100] train error: 0.725392, test error: 0.993935\n",
      "[Epoch 84/100] train error: 0.724599, test error: 0.993476\n",
      "[Epoch 85/100] train error: 0.723821, test error: 0.993032\n",
      "[Epoch 86/100] train error: 0.723059, test error: 0.992602\n",
      "[Epoch 87/100] train error: 0.722312, test error: 0.992185\n",
      "[Epoch 88/100] train error: 0.721580, test error: 0.991780\n",
      "[Epoch 89/100] train error: 0.720862, test error: 0.991388\n",
      "[Epoch 90/100] train error: 0.720157, test error: 0.991008\n",
      "[Epoch 91/100] train error: 0.719466, test error: 0.990638\n",
      "[Epoch 92/100] train error: 0.718787, test error: 0.990280\n",
      "[Epoch 93/100] train error: 0.718121, test error: 0.989932\n",
      "[Epoch 94/100] train error: 0.717468, test error: 0.989594\n",
      "[Epoch 95/100] train error: 0.716826, test error: 0.989265\n",
      "[Epoch 96/100] train error: 0.716195, test error: 0.988946\n",
      "[Epoch 97/100] train error: 0.715576, test error: 0.988636\n",
      "[Epoch 98/100] train error: 0.714968, test error: 0.988334\n",
      "[Epoch 99/100] train error: 0.714371, test error: 0.988041\n",
      "[Epoch 100/100] train error: 0.713784, test error: 0.987755\n",
      "Algorithm converged\n"
     ]
    }
   ],
   "source": [
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "#Only consider non-zero matrix \n",
    "users,items = R.nonzero()      \n",
    "for epoch in range(n_epochs):\n",
    "    for u, i in zip(users,items):\n",
    "        e = R[u, i] - prediction(P[:,u],Q[:,i])  # Calculate error for gradient\n",
    "        P[:,u] += gamma * ( e * Q[:,i] - lmbda * P[:,u]) # Update latent user feature matrix\n",
    "        Q[:,i] += gamma * ( e * P[:,u] - lmbda * Q[:,i])  # Update latent movie feature matrix\n",
    "    train_rmse = rmse(I,R,Q,P) # Calculate root mean squared error from train dataset\n",
    "    test_rmse = rmse(I2,T,Q,P) # Calculate root mean squared error from test dataset\n",
    "    train_errors.append(train_rmse)\n",
    "    test_errors.append(test_rmse)\n",
    "    \n",
    "    print (\"[Epoch %d/%d] train error: %f, test error: %f\" \\\n",
    "    %(epoch+1, n_epochs, train_rmse, test_rmse))\n",
    "\n",
    "print(\"Algorithm converged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como foram guardados todos os  ``train_errors`` e ``test_errors`` para cada época, podemos plotar as curva de aprendizagem do algoritmo SGD-WR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMMYY08ySgjHGmGaWFIwxxjT7f+GWqB0fTFLAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0d904e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check performance by plotting train and test errors\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(n_epochs), train_errors, marker='o', label='Training Data');\n",
    "plt.plot(range(n_epochs), test_errors, marker='v', label='Test Data');\n",
    "plt.title('SGD-WR Learning Curve')\n",
    "plt.xlabel('Number of Epochs');\n",
    "plt.ylabel('RMSE');\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo parece se comportar muito bem, com um RMSE relativamente baixo apor convergir. A performance pode ser influenciada através da calibragem dos parâmetros $\\lambda$, $\\gamma$ and $k$.\n",
    "\n",
    "\n",
    "A seguir tu podes comparar o rating real com o rating predito. Para isso, primeiro calcula-se a matriz de rating preditos - para a qual utilizaremos a função ``prediction`` que foi definida anteriormente, e converter a matriz em um dataframe para facilitar o uso. <img src=\"https://latex.codecogs.com/gif.latex?\\hat&space;r_{ui}=P_u^TQ_i$&space;&space;$(2)\" title=\"\\hat r_{ui}=p_u^Tq_i\" /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate prediction matrix R_hat (low-rank approximation for R)\n",
    "R = pd.DataFrame(R)\n",
    "R_hat=pd.DataFrame(prediction(P,Q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para se ter uma ideia do que foi atingido, vamos comparar algumas de nossas predições para o usuário ``29`` com seus ratings reais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Rating</th>\n",
       "      <th>Predicted Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.641876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.901989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.250651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.175654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.828347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual Rating  Predicted Rating\n",
       "11             5.0          4.641876\n",
       "78             4.0          3.901989\n",
       "97             4.0          4.250651\n",
       "179            4.0          4.175654\n",
       "181            4.0          3.828347"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare true ratings of user 17 with predictions\n",
    "ratings = pd.DataFrame(data=R.loc[28,R.loc[28,:] > 0]).head(n=5)\n",
    "ratings['Prediction'] = R_hat.loc[28,R.loc[28,:] > 0]\n",
    "ratings.columns = ['Actual Rating', 'Predicted Rating']\n",
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências\n",
    "- [Koren et al. (2009)](http://citeseer.ist.psu.edu/viewdoc/download;jsessionid=8413B85890576DE006023342D58E8E67?doi=10.1.1.147.8295&rep=rep1&type=pdf) Koren, Y., Bell, R.M., Volinsky, C.: Matrix factorization techniques for recommender systems. IEEE Computer 42(8), 30–37 (2009) 32 Francesco Ricci, Lior Rokach and Bracha Shapira"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<strong>Este tutorial foi adaptado a partir do tutorial de Agnes Johannsdottir e Moritz Haller.</strong>\n",
    "\n",
    "Agnes is a master student in Business Analytics at University College London. She studied Management Engineering in Iceland and worked for 2 years as an IT consultant in supply chain. Her main interests lie in using data science methods (especially machine learning) to apply in Retail and Supply Chain businesses.\n",
    "\n",
    "Moritz has spent the past years in industry, working on business intelligence applications with the company he co-founded. He holds a BSc in Computer Science and is currently pursuing an MSc in Computer Science at University College London. His main interests lie in probabilistic modelling and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
